{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Map of countries by emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // 1.  Import packages that we need:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# // Web scraping: \n",
    "import requests\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "# // OS. Sometimes need this for finding working directory:\n",
    "import os\n",
    "# // datetime\n",
    "from datetime import datetime\n",
    "# // regex library used to detect the presence of particular characters (eg extarcting numbers from string)\n",
    "import re\n",
    "from pprint import pprint \n",
    "\n",
    "# // package to convert country names and iso codes, eg United States of America -> USA / US\n",
    "import country_converter as coco\n",
    "# // for loading JSON data \n",
    "import json\n",
    "import geopandas\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Loop to create list of all countries for 'Electricity net consumption, {}, Annual' Dataset\n",
    "\n",
    "URL = \"https://www.eia.gov/opendata/qb.php?category=2622652\"\n",
    "\n",
    "# // Request the html from the URL:\n",
    "html = requests.get(URL)\n",
    "\n",
    "# // Get the soup of this page\n",
    "soup = BeautifulSoup(html.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use css selector to extract only relevent links\n",
    "names = soup.select('div.main_col ul > li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Africa not found in regex\n",
      "Asia & Oceania not found in regex\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "More then one regular expression match for Australia and New Zealand\n",
      "Central & South America not found in regex\n",
      "Eurasia not found in regex\n",
      "Europe not found in regex\n",
      "European Union not found in regex\n",
      "Former Serbia and Montenegro not found in regex\n",
      "Former U.S.S.R. not found in regex\n",
      "Former Yugoslavia not found in regex\n",
      "Hawaiian Trade Zone not found in regex\n",
      "IEO - Africa not found in regex\n",
      "IEO - Middle East not found in regex\n",
      "IEO OECD - Europe not found in regex\n",
      "Middle East not found in regex\n",
      "Netherlands Antilles not found in regex\n",
      "Non-OECD not found in regex\n",
      "Non-OPEC not found in regex\n",
      "North America not found in regex\n",
      "OECD - Asia And Oceania not found in regex\n",
      "OECD - Europe not found in regex\n",
      "OECD - North America not found in regex\n",
      "OECD not found in regex\n",
      "OPEC - Africa not found in regex\n",
      "OPEC - South America not found in regex\n",
      "OPEC not found in regex\n",
      "Other Non-OECD - America not found in regex\n",
      "Other Non-OECD - Asia not found in regex\n",
      "Other Non-OECD - Europe and Eurasia not found in regex\n",
      "U.S. Pacific Islands not found in regex\n",
      "U.S. Territories not found in regex\n",
      "Wake Island not found in regex\n",
      "World not found in regex\n"
     ]
    }
   ],
   "source": [
    "# 1. find all countries with links to API on eia page\n",
    "# 2. extract only country name\n",
    "# 3. then use ISO converter to find character code for each country name\n",
    "# 4. ready to feed through loop to individually fetch data from each country's api link\n",
    "\n",
    "\n",
    "countries = []\n",
    "for i in range(len(soup.select('div.main_col ul > li'))):\n",
    "    # take text of ith list string \n",
    "    to_strip = names[i].text.strip()\n",
    "    # split on commas as country always contained within\n",
    "    chunks = to_strip.split(', ')\n",
    "    # add to master 2nd element to country list\n",
    "    countries.append(chunks[1])\n",
    "\n",
    "# create dataframe of results\n",
    "df_c = pd.DataFrame(countries)\n",
    "\n",
    "# create new column of ISO 3 codes\n",
    "# // this has the plus of making it easy to auto-strip out non country data links (eg OECD or World)\n",
    "df_c['ISO3'] = coco.convert(df_c[0], to='ISO3')\n",
    "\n",
    "\n",
    "# drop all rows with \"not found\" for ISO3 code, eg EU / OECD\n",
    "df_c = df_c[df_c['ISO3'].str.contains(\"not found\")==False]\n",
    "\n",
    "# drop row for Antarctica (inconsistent and low value data)\n",
    "df_c = df_c[df_c['ISO3'].str.contains(\"ATA\")==False]\n",
    "\n",
    "# drops rows with duplicates values in 'Country' or ISO3, duplicate ISO codes for some areas, eg \n",
    "#   former Czechoslovakia and Czechia give CZE (although API link for former is different), fortunately in api the ISO3\n",
    "#    codes will only give data for the current country so effectively cleans results of old time-series\n",
    "df_c = df_c.drop_duplicates(subset=[0], keep='first')\n",
    "df_c = df_c.drop_duplicates(subset=['ISO3'], keep='first')\n",
    "\n",
    "# reset index and drop old index\n",
    "df_c.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Use converter in reverse to give standard format names to all countries ...\n",
    "#   (happened because converting and dropping duplicates left some mismatched eg: 'South Korea and other Asia' ...\n",
    "#    was matched with 'KOR' instead of being dropped like OECD was)\n",
    "df_c[0] = coco.convert(df_c['ISO3'], to='name_short')\n",
    "\n",
    "df_c.columns = ['Country', 'ISO3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now build loop to retrieve api results from every country in table\n",
    "    # build in tidy data format\n",
    "\n",
    "API_Key = \"cKNHOE6oTscEBlfP9TF7LXFAK68fOfbzhTVn3HO0\"\n",
    "\n",
    "# // Set the base url for:\n",
    "#   'CO2 Emissions, annual, million metric tonnes'\n",
    "url_base = \"http://api.eia.gov/series/?api_key=cKNHOE6oTscEBlfP9TF7LXFAK68fOfbzhTVn3HO0&series_id=INTL.4008-8-{}-MMTCD.A\"\n",
    "\n",
    "\n",
    "# // create list of ISO3 codes (have to add .to_list() otherwise it just returns a pandas series and 'c in codes' wont work)\n",
    "codes = df_c['ISO3'].to_list()\n",
    "\n",
    "# ** Kosovo does not have official iso3 code, coco assigned XKX but EIA uses XKS, so manually change otherwise \n",
    "#  loop breaks at 'for i in data['series']:' on Kosovo iteration\n",
    "for i in range(len(codes)):\n",
    "    if codes[i] == 'XKX':\n",
    "        codes[i] = 'XKS'\n",
    "\n",
    "# // create empty df\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for c in codes:\n",
    "\n",
    "    # // Return the index number of the thing we are working with:\n",
    "    s = codes.index(c)\n",
    "\n",
    "    # // Build the URL for this iteration of the loop:\n",
    "    URL = url_base.format(c)\n",
    "\n",
    "    # // Request the html from the URL:\n",
    "    data = requests.get(URL).json()\n",
    "\n",
    "    # // build template array\n",
    "    base_array = np.array(['Year', 'mtonnes CO2', 'Country'])\n",
    "\n",
    "\n",
    "    for i in data['series']:\n",
    "        \n",
    "        # add all timeseries data to array (format is [Year, <value>])\n",
    "        array_i = np.array(i['data'])\n",
    "\n",
    "        # add column with country code in every row\n",
    "        array_i = np.insert(array_i,array_i.shape[1],c,axis=1)\n",
    "\n",
    "        # add headers for first result\n",
    "        if s == 0:\n",
    "            array_i = np.vstack((base_array, array_i))\n",
    "\n",
    "        # // Convert array into temporary dataframe:\n",
    "        df_x = pd.DataFrame(array_i)\n",
    "\n",
    "        # drops any obersations with NA\n",
    "        df_x = df_x[df_x[1].str.contains(\"NA\")==False]\n",
    "\n",
    "        # concat temp df with main df\n",
    "        df = pd.concat([df, df_x], ignore_index=True)\n",
    "\n",
    "# set first row as headers and delete row\n",
    "df.columns = df.iloc[0]\n",
    "df = df.iloc[1: , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>mtonnes CO2</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>7.893076967</td>\n",
       "      <td>AFG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>9.391163087</td>\n",
       "      <td>AFG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>7.886124149</td>\n",
       "      <td>AFG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>7.279395964</td>\n",
       "      <td>AFG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015</td>\n",
       "      <td>7.852509211</td>\n",
       "      <td>AFG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8747</th>\n",
       "      <td>1984</td>\n",
       "      <td>7.783562489</td>\n",
       "      <td>ZWE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8748</th>\n",
       "      <td>1983</td>\n",
       "      <td>7.584832144</td>\n",
       "      <td>ZWE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8749</th>\n",
       "      <td>1982</td>\n",
       "      <td>7.332897573</td>\n",
       "      <td>ZWE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8750</th>\n",
       "      <td>1981</td>\n",
       "      <td>7.531253431</td>\n",
       "      <td>ZWE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8751</th>\n",
       "      <td>1980</td>\n",
       "      <td>7.673434383</td>\n",
       "      <td>ZWE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8751 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0     Year  mtonnes CO2 Country\n",
       "1     2019  7.893076967     AFG\n",
       "2     2018  9.391163087     AFG\n",
       "3     2017  7.886124149     AFG\n",
       "4     2016  7.279395964     AFG\n",
       "5     2015  7.852509211     AFG\n",
       "...    ...          ...     ...\n",
       "8747  1984  7.783562489     ZWE\n",
       "8748  1983  7.584832144     ZWE\n",
       "8749  1982  7.332897573     ZWE\n",
       "8750  1981  7.531253431     ZWE\n",
       "8751  1980  7.673434383     ZWE\n",
       "\n",
       "[8751 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build dataframe for population\n",
    "\n",
    "pop_url = \"http://api.eia.gov/series/?api_key=cKNHOE6oTscEBlfP9TF7LXFAK68fOfbzhTVn3HO0&series_id=INTL.4702-33-{}-THP.A\"\n",
    "\n",
    "\n",
    "# // create empty df\n",
    "df_pop = pd.DataFrame()\n",
    "\n",
    "for c in codes:\n",
    "\n",
    "    # // Return the index number of the thing we are working with:\n",
    "    s = codes.index(c)\n",
    "\n",
    "    # // Build the URL for this iteration of the loop:\n",
    "    URL = pop_url.format(c)\n",
    "\n",
    "    # // Request the html from the URL:\n",
    "    data = requests.get(URL).json()\n",
    "\n",
    "    # // build template array\n",
    "    base_array = np.array(['Year', 'Population', 'Country'])\n",
    "\n",
    "\n",
    "    for i in data['series']:\n",
    "        \n",
    "        # add all timeseries data to array (format is [Year, <value>])\n",
    "        array_i = np.array(i['data'])\n",
    "\n",
    "        # add column with country code in every row\n",
    "        array_i = np.insert(array_i,array_i.shape[1],c,axis=1)\n",
    "\n",
    "        # add headers for first result\n",
    "        if s == 0:\n",
    "            array_i = np.vstack((base_array, array_i))\n",
    "\n",
    "        # // Convert array into temporary dataframe:\n",
    "        df_x = pd.DataFrame(array_i)\n",
    "\n",
    "        # drops any obersations with NA\n",
    "        df_x = df_x[df_x[1].str.contains(\"NA\")==False]\n",
    "\n",
    "        # concat temp df with main df\n",
    "        df_pop = pd.concat([df_pop, df_x], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set first row as headers and delete row\n",
    "df_pop.columns = df_pop.iloc[0]\n",
    "df_pop = df_pop.iloc[1: , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract 2019 data from each dataframe\n",
    "\n",
    "co2_2019 = df[df.Year == '2019']\n",
    "pop_2019 = df_pop[df_pop.Year == '2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XKS not found in ISO3\n"
     ]
    }
   ],
   "source": [
    "## merge datasets\n",
    "\n",
    "merge = pd.merge(\n",
    "    co2_2019,\n",
    "    pop_2019,\n",
    "    how=\"inner\",\n",
    "    on=\"Country\",\n",
    "    left_index=False,\n",
    "    right_index=False,\n",
    "    sort=True,\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    "    validate=None,\n",
    ")\n",
    "\n",
    "# calculate emissions per capita\n",
    "# -- pop in thousands, emissions in millions\n",
    "merge = merge.astype({\"mtonnes CO2\": float, \"Population\": float})\n",
    "\n",
    "\n",
    "merge[\"CO2 emissions per capita (t)\"] = (1000*merge['mtonnes CO2'])/merge['Population']\n",
    "\n",
    "# // rename columns\n",
    "merge.columns = ['Year', 'CO2 (million t)', 'ISO3', 'Year', 'Population', 'CO2 emissions per capita (t)']\n",
    "\n",
    "# drop duplicate column\n",
    "merge = merge.drop(columns=['Year'])\n",
    "\n",
    "# round main data for better presentation later\n",
    "merge['CO2 emissions per capita (t)'] = merge['CO2 emissions per capita (t)'].round(3)\n",
    "\n",
    "# format pop as actual\n",
    "merge['Population'] = merge['Population']*1000\n",
    "merge = merge.astype({\"Population\": int})\n",
    "\n",
    "merge['Country'] = coco.convert(merge['ISO3'], to='name_short')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with geojson\n",
    "\n",
    "# import country geojson by Natural Earth, downloaded from https://datahub.io/core/geo-countries#pandas \n",
    "geojson = geopandas.read_file('/Users/joshhellings/Documents/OneDrive - University of Bristol/Economics Year 3/Data Science/Project data/globalMap.geojson')\n",
    "\n",
    "# merge geojson and data\n",
    "full_dataset = geojson.merge(merge, left_on=\"ISO_A3\", right_on=\"ISO3\")\n",
    "\n",
    "full_dataset.to_file(\"/Users/joshhellings/Documents/OneDrive - University of Bristol/Economics Year 3/Data Science/Github Mirror/Project/Data/emissions_perCapita.geojson\", driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO2 (million t)</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population</th>\n",
       "      <th>CO2 emissions per capita (t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.254453</td>\n",
       "      <td>ABW</td>\n",
       "      <td>106298</td>\n",
       "      <td>11.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.893077</td>\n",
       "      <td>AFG</td>\n",
       "      <td>38050900</td>\n",
       "      <td>0.207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.361933</td>\n",
       "      <td>AGO</td>\n",
       "      <td>31849800</td>\n",
       "      <td>0.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.794238</td>\n",
       "      <td>ALB</td>\n",
       "      <td>2879920</td>\n",
       "      <td>1.317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276.211962</td>\n",
       "      <td>ARE</td>\n",
       "      <td>9764900</td>\n",
       "      <td>28.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>8.019692</td>\n",
       "      <td>XKS</td>\n",
       "      <td>1794250</td>\n",
       "      <td>4.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>10.366728</td>\n",
       "      <td>YEM</td>\n",
       "      <td>29162200</td>\n",
       "      <td>0.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>470.358047</td>\n",
       "      <td>ZAF</td>\n",
       "      <td>58650230</td>\n",
       "      <td>8.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>6.798094</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>17873850</td>\n",
       "      <td>0.380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>7.966678</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>14654200</td>\n",
       "      <td>0.544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CO2 (million t) Country  Population  CO2 emissions per capita (t)\n",
       "0           1.254453     ABW      106298                        11.801\n",
       "1           7.893077     AFG    38050900                         0.207\n",
       "2          19.361933     AGO    31849800                         0.608\n",
       "3           3.794238     ALB     2879920                         1.317\n",
       "4         276.211962     ARE     9764900                        28.286\n",
       "..               ...     ...         ...                           ...\n",
       "197         8.019692     XKS     1794250                         4.470\n",
       "198        10.366728     YEM    29162200                         0.355\n",
       "199       470.358047     ZAF    58650230                         8.020\n",
       "200         6.798094     ZMB    17873850                         0.380\n",
       "201         7.966678     ZWE    14654200                         0.544\n",
       "\n",
       "[202 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "113903349309e73f3a7191f616987ae20874fe83f45c68fdab869fbcd5d05197"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
